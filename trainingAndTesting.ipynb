{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and testing with different classifiers\n",
    "\n",
    "This notebook contains code to apply different ml models to the pre-processed recipe-ingredient dataset. For pre-processing, check the other notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk import WordNetLemmatizer\n",
    "import inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "df = pd.read_json('dataset.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset and pre-processing based on understanding of previous EDA.\n",
    "1. Converting text into lowercase\n",
    "2. Removing leading and trailing whitespace\n",
    "3. Removing punctuation, numbers and special characters\n",
    "4. Replacing plural words with singular versions\n",
    "5. Lemmatizing the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = WordNetLemmatizer() # lemmatizing instead of stemming to preserve context\n",
    "p = inflect.engine() # to change to singular instead of stemming\n",
    "\n",
    "def format_ingredients(ingredient_list):\n",
    "    formatted = [ing.strip().lower() for ing in ingredient_list]\n",
    "    alpha = [(''.join(char for char in ing if char.isalpha())) for ing in formatted]\n",
    "    singular = [p.singular_noun(ing) or ing for ing in alpha]\n",
    "    lemmatized = [wn.lemmatize(ing) for ing in singular]\n",
    "    return (', '.join(lemmatized))\n",
    "\n",
    "df['ingredients_formatted'] = df['ingredients'].apply(lambda x: format_ingredients(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing\n",
    "\n",
    "The ingredient list is already tokenized (as an array of ingredients), but needs to be vectorized (i.e. encoded so as to be able to create feature vectors for the machine learning algorithms to train/test)\n",
    "\n",
    "Apply TF-IDF vectorization on the dataset, and transform it to a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39774, 6636)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english', analyzer='word', max_df=0.8, token_pattern=r'\\w+')\n",
    "x_tfidf = tfidf.fit_transform(df['ingredients_formatted'])\n",
    "print(x_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "Asses the performance of models, parameters used here are selected based on experiementation. \n",
    "All scripts for random variations/param tuning/grid search that led to selection of these particular values can be found in the [`/scripts`](https://github.com/nutellaweera/ML_Assignment/tree/main/scripts) folder. \n",
    "\n",
    "Code for below is adapted from the 'Batter of Algorithms' code included in the Learning Material (revision) section (Phoebe Pring + HI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_tfidf, df['cuisine'], random_state=42, shuffle=True)\n",
    "\n",
    "models = [\n",
    "    ('K Nearest Neighbor', KNeighborsClassifier(n_neighbors=17, metric='euclidean')),\n",
    "    ('Logistic Regression', LogisticRegression(max_iter=50, multi_class='multinomial')),\n",
    "    ('Naive Bayes', MultinomialNB(alpha=0.01)),\n",
    "    ('Random Forest', RandomForestClassifier(bootstrap=True, criterion='gini', min_samples_split=2, n_estimators=200)),\n",
    "]\n",
    "\n",
    "results = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=12, shuffle=True, random_state=42)\n",
    "    results.append((name, cross_val_score(model, x_train, y_train, cv=kfold, scoring='accuracy')))\n",
    "\n",
    "print(results)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad4efc98168ab38b08e64aa2fc02055880fa9a8646a17501f53b605319231c71"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

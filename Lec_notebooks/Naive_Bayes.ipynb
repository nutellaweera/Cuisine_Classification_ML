{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive Bayes.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWsf4ZvPjnIE"
      },
      "source": [
        "This is a snippit of the code from Previous Coursework submission (EXample5 on Predicting Deceptive Hotel Reviews).\n",
        "\n",
        "\n",
        "## Tasks **A** ##\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Please note code with the provided settings will take sometime to train and run\n",
        "— there's cross validation.\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "1.   Code claims classifiers were tuned by a GridSearch, there's no evidence on that — can you tune for the models you know using nested cross validation? \n",
        "2.   Add a StackingClassifier besides the VotingClassifier (last week tutorial you were provided with a`VotingClassifier` - to add (example on how from sklearn):\n",
        "\n",
        "\n",
        "```\n",
        "estimators = [\n",
        "     ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
        "     ('svr', make_pipeline(StandardScaler(),\n",
        "                           LinearSVC(random_state=42)))\n",
        " ]\n",
        "clf = StackingClassifier(\n",
        "     estimators=estimators, final_estimator=LogisticRegression()\n",
        " )\n",
        " ```\n",
        "and report results. \n",
        "\n",
        "\n",
        "# 3.   Can you \"beat\" previous student accuracy results — if you would, report your accuracy outcomes, send me an e-mail and get a prize! \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "rbC3mu0yiQ40",
        "outputId": "4aa678ed-da17-44ce-a025-96eadac1e60a"
      },
      "source": [
        "\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sat Jul 21 13:21:01 2018\n",
        "\n",
        "@author: Former Student Ph. P\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "#read data \n",
        "hotel_reviews = pd.read_csv('hotel_reviews_raw_data.csv')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#drop duplicate values\n",
        "hotel_reviews.drop_duplicates(['text'], inplace=True)\n",
        "#hotel_reviews.drop(['polarity'], 1, inplace=True)\n",
        "\n",
        "#encode label\n",
        "le = LabelEncoder()\n",
        "label = le.fit_transform(hotel_reviews['deceptive'])\n",
        "\n",
        "#define X and y\n",
        "X = np.array(hotel_reviews['text'])\n",
        "y = np.array(label)\n",
        "\n",
        "# encoding polarity.\n",
        "P = le.fit_transform(hotel_reviews['polarity'])\n",
        "Polarity = np.array(P).reshape(1596,1)\n",
        "print (Polarity.shape)\n",
        "\n",
        "#turn text into numeric feature vectors\n",
        "#vec = CountVectorizer(stop_words='english', ngram_range=(1,3))\n",
        "#reviews = vec.fit_transform(X) #vocabulary created using all data\n",
        "\n",
        "\n",
        "vec = CountVectorizer(stop_words='english', ngram_range=(1,2)).fit(X)\n",
        "reviews = vec.transform(X)\n",
        "print(\"X_train:\\n{}\".format(repr(X)))\n",
        "\n",
        "\n",
        "\n",
        "feature_names = vec.get_feature_names()\n",
        "print(\"Number of features: {}\".format(len(feature_names)))\n",
        "print(\"First 20 features:\\n{}\".format(feature_names[:20]))\n",
        "print(\"Features 20010 to 20030:\\n{}\".format(feature_names[20010:20030]))\n",
        "print(\"Every 2000th feature:\\n{}\".format(feature_names[::2000]))\n",
        "\n",
        "Reviews_with_Polarity = np.append(reviews.todense(), Polarity, axis=1)\n",
        "#print (Reviews_with_Polarity[:,9284])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    Reviews_with_Polarity, y, random_state=0, shuffle=True)\n",
        "#NOTE: to include Polarity replace 'reviews' with 'Reviews_with_Polarity' in the splitting above.\n",
        "\n",
        "#train random forest classifier\n",
        "clf = RandomForestClassifier(bootstrap=True, max_features='auto', n_estimators=100, max_depth=None,min_samples_split=5, random_state=7, oob_score=True)\n",
        "clf.fit(X_train,y_train)\n",
        "\n",
        "#Get feature names\n",
        "names = vec.get_feature_names()\n",
        "\n",
        "#print features and importance scores\n",
        "#print (sorted(zip(map(lambda x: round(x, 4), clf.feature_importances_), names), reverse=True))\n",
        "\n",
        "#create subset of features\n",
        "sfm = SelectFromModel(clf, threshold=0.00015)\n",
        "\n",
        "sfm.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "#X_best_features_train = sfm.transform(X_train)\n",
        "#X_best_features_test = sfm.transform(X_test)\n",
        "X_best_features_train = X_train\n",
        "X_best_features_test = X_test\n",
        "\n",
        "\n",
        "#prepare algorithms to test\n",
        "models = []\n",
        "models.append(('NB', MultinomialNB()))\n",
        "models.append(('kNN', KNeighborsClassifier(n_neighbors = 10)))\n",
        "models.append(('LogR', LogisticRegression()))\n",
        "models.append(('SVC', SVC(C=10, gamma=0.001))) #model is tuned using GridSearch (code in seperate file)\n",
        "models.append(('DT', tree.DecisionTreeClassifier()))\n",
        "models.append(('RF', RandomForestClassifier(bootstrap=True, max_features='auto', n_estimators=50, max_depth=None,min_samples_split=5, random_state=7)))\n",
        "models.append(('AdaB', AdaBoostClassifier()))\n",
        "\n",
        "\n",
        "\n",
        "#evaluate each algorithm\n",
        "results = []\n",
        "names = []\n",
        "for name, model in models:\n",
        "    #If not statified, shuffle is vital given data is ordered by labels.\n",
        "    kfold = KFold(n_splits=10, shuffle=True, random_state=7)\n",
        "    cv_results = cross_val_score(model, X_best_features_train, y_train, cv=kfold, scoring='accuracy')\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    print( \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std()))\n",
        "    \n",
        "#boxplot algorithm comparison\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1596, 1)\n",
            "X_train:\n",
            "array(['We stayed for a one night getaway with family on a thursday. Triple AAA rate of 173 was a steal. 7th floor room complete with 44in plasma TV bose stereo, voss and evian water, and gorgeous bathroom(no tub but was fine for us) Concierge was very helpful. You cannot beat this location... Only flaw was breakfast was pricey and service was very very slow(2hours for four kids and four adults on a friday morning) even though there were only two other tables in the restaurant. Food was very good so it was worth the wait. I would return in a heartbeat. A gem in chicago... \\n',\n",
            "       'Triple A rate with upgrade to view room was less than $200 which also included breakfast vouchers. Had a great view of river, lake, Wrigley Bldg. & Tribune Bldg. Most major restaurants, Shopping, Sightseeing attractions within walking distance. Large room with a very comfortable bed. \\n',\n",
            "       \"This comes a little late as I'm finally catching up on my reviews from the past several months:) A dear friend and I stayed at the Hyatt Regency in late October 2007 for one night while visiting a friend and her husband from out of town. This hotel is perfect, IMO. Easy check in and check out. Lovely, clean, comfortable rooms with great views of the city. I know this area pretty well and it's very convenient to many downtown Chicago attractions. We had dinner and went clubing with our friends around Division St.. We had no problems getting cabs back and forth to the Hyatt and there's even public transportation right near by but we didn't bother since we only needed cabs from and to the hotel. Parking, as is usual for Chicago, was expensive but we were able to get our car out quickly (however, we left on a Sunday morning, not exactly a high traffic time although it was a Bears homegame day, so a bit busier than usual I would think). No problems at all and the best part is that we got a rate of $100 through Hotwire, a downright steal for this area of Chicago and the quality of the hotel. \\n\",\n",
            "       ...,\n",
            "       'The Intercontinental Chicago Magnificent Mile The outside of the hotel itself is as the name says is pretty magnificent despite being set in what has to be the filthiest section in the city. For the cost of the rooms starting at 179.00 a night, you would think they would have a competent parking attendant. I was delayed from a very important client due to a latency issue with my reserved room, and if that was not enough. To top it off the room service had the nerve to bring up room temperature pasta and a bottle of champagne that had the seal previously broken free of the cork. Needless to say this will be the last time this hotel ever is to grace so much as another dollar bill from my account. I would highly recommend another hotel with better accommodations.\\n',\n",
            "       \"The Palmer House Hilton, while it looks good in pictures, and the outside, is actually a disaster of a hotel. When I went through, the lobby was dirty, my room hadn't been cleaned, and smelled thoroughly of smoke. When I requested more pillows, the lady on the phone scoffed at me and said she'd send them up. It took over an hour for 2 pillows. This hotel is a good example that what you pay for isn't always what you get. I will not be returning.\\n\",\n",
            "       \"As a former Chicagoan, I'm appalled at the Amalfi Hotel Chicago. First of all, I was expecting luxury and hospitality, neither of which I received. There's an Experience Designer who is supposed to be like a 'personal concierge,' but my experience with my ED was terrible. I felt like he was trying to pressure me into staying more days than I wanted to. Not only that, but I couldn't understand what he was saying most of the time because he was talking so fast. When I finally got to my room, I was disappointed with the quality of the furniture and the room's cleanliness. I had to ask for a maid to come and give me clean towels because some of the towels in the bathroom were damp. On top of that, the bed was messily done; I could have done a better job on my own bed at home. I was angry at this point, because I was paying a lot of money for every night I was staying at Amalfi, and I didn't expect to be greeted with wet towels. I needed to use the Wi-Fi to download some important documents, and the internet was surprisingly slow. Even a very basic hotel or motel could have offered better, maybe even faster internet access. When I finally checked out of the Amalfi, I made sure that my supposed personal concierge knew all of the problems I'd had with my room and the hotel. I was glad to see the Amalfi getting smaller in the mirror as I drove away!\\n\"],\n",
            "      dtype=object)\n",
            "Number of features: 81609\n",
            "First 20 features:\n",
            "['00', '00 24', '00 aaa', '00 able', '00 added', '00 bottle', '00 bucks', '00 buy', '00 called', '00 compared', '00 complain', '00 day', '00 did', '00 disappointed', '00 fare', '00 free', '00 friday', '00 given', '00 great', '00 luxury']\n",
            "Features 20010 to 20030:\n",
            "['desk curbside', 'desk customers', 'desk dark', 'desk day', 'desk decided', 'desk delivered', 'desk demanded', 'desk designer', 'desk desk', 'desk did', 'desk didn', 'desk disorganized', 'desk doorman', 'desk downright', 'desk efficient', 'desk employee', 'desk employees', 'desk ended', 'desk experience', 'desk explain']\n",
            "Every 2000th feature:\n",
            "['00', 'add room', 'area great', 'backtrack hotel', 'best bathrooms', 'building street', 'charge wifi', 'clean bed', 'complicated', 'crew did', 'desk cleverly', 'doesnt', 'encountered modern', 'extra chair', 'flight sighed', 'generally speaking', 'guess paint', 'historic feel', 'hour stop', 'intercontinental weekend', 'lamb chops', 'load bearing', 'maintained luxury', 'minutes end', 'nice let', 'online advantage', 'people charge', 'pool looked', 'questions', 'relieved provided', 'rock', 'said fixed', 'shabbiness poor', 'smaller having', 'stained', 'style minimalist', 'thats curtains', 'towers days', 'unique traits', 'walked art', 'wife week']\n",
            "NB: 0.871366 (0.029839)\n",
            "kNN: 0.507843 (0.036567)\n",
            "LogR: 0.857143 (0.041940)\n",
            "SVC: 0.861331 (0.039695)\n",
            "DT: 0.677577 (0.038216)\n",
            "RF: 0.860490 (0.027628)\n",
            "AdaB: 0.813761 (0.041142)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzwfSXZXofcI"
      },
      "source": [
        "## Tasks **B** ##\n",
        "Apply the predictors you learnt on the [The 20 newsgroups text dataset](https://scikit-learn.org/stable/datasets/real_world.html#newsgroups-dataset). How far your accuracy results can get?\n",
        "\n",
        "\n",
        "```\n",
        "Note: code on MultinomilaNB is provided in scikit-learn documentaion. Same link above.\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mE_Xz4j9qTiX"
      },
      "source": [
        "## Tasks **C** ##\n",
        "On the Iris Dataset of all target classes:\n",
        "\n",
        "\n",
        "1.   What models would provide multiclass classifications.\n",
        "\n",
        "\n",
        "> Apply them to do the job — cheating here: would you try multinomial logistic regression?\n",
        "\n",
        "\n",
        "2.   Check the One Vs All multiclass classifiers on scikit learn documentation and apply those you have been learning over previous weeks. \n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}
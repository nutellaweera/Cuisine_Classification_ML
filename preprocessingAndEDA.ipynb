{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and EDA\n",
    "\n",
    "This notebook contains code for pre-processing and some exploratory analysis of the [whats-cooking dataset from Kaggle](https://www.kaggle.com/datasets/kaggle/recipe-ingredients-dataset), carried out with the aim of understanding the dataset and planning next steps for implimentation of a predictive ml model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling as ProfileReport\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "Reading the json dataset into a pd dataframe and generating an EDA using pandas_profiling (found in index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id      cuisine                                        ingredients\n",
      "0  10259        greek  [romaine lettuce, black olives, grape tomatoes...\n",
      "1  25693  southern_us  [plain flour, ground pepper, salt, tomatoes, g...\n",
      "2  20130     filipino  [eggs, pepper, salt, mayonaise, cooking oil, g...\n",
      "3  22213       indian                [water, vegetable oil, wheat, salt]\n",
      "4  13162       indian  [black pepper, shallots, cornflour, cayenne pe...\n",
      "(39774, 3)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json('dataset.json')\n",
    "print(df.head())\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "# profile = ProfileReport(df, title=\"EDA\")\n",
    "# profile.to_file('index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "Understanding the types of cuisine and number of recipes for each type of cuisine - there are 20 types of cuisines, mostly italian and mexican."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "italian         7838\n",
       "mexican         6438\n",
       "southern_us     4320\n",
       "indian          3003\n",
       "chinese         2673\n",
       "french          2646\n",
       "cajun_creole    1546\n",
       "thai            1539\n",
       "japanese        1423\n",
       "greek           1175\n",
       "spanish          989\n",
       "korean           830\n",
       "vietnamese       825\n",
       "moroccan         821\n",
       "british          804\n",
       "filipino         755\n",
       "irish            667\n",
       "jamaican         526\n",
       "russian          489\n",
       "brazilian        467\n",
       "Name: cuisine, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cuisine'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "Converting the ingredients into lowercase and adding a col to the dataset with the ingredients in string form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id      cuisine                                        ingredients  \\\n",
      "0  10259        greek  [romaine lettuce, black olives, grape tomatoes...   \n",
      "1  25693  southern_us  [plain flour, ground pepper, salt, tomatoes, g...   \n",
      "2  20130     filipino  [eggs, pepper, salt, mayonaise, cooking oil, g...   \n",
      "3  22213       indian                [water, vegetable oil, wheat, salt]   \n",
      "4  13162       indian  [black pepper, shallots, cornflour, cayenne pe...   \n",
      "\n",
      "                                     ingredients_str  \n",
      "0  romaine lettuce, black olives, grape tomatoes,...  \n",
      "1  plain flour, ground pepper, salt, tomatoes, gr...  \n",
      "2  eggs, pepper, salt, mayonaise, cooking oil, gr...  \n",
      "3                  water, vegetable oil, wheat, salt  \n",
      "4  black pepper, shallots, cornflour, cayenne pep...  \n"
     ]
    }
   ],
   "source": [
    "df['ingredients_str'] = [', '.join(x).strip().lower() for x in df['ingredients']]\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4\n",
    "Checking the number of unique ingredients - 6714, most and least common ingredients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique ingredients >> 6714\n",
      "most common ingredients >>> [('salt', 18049), ('onions', 7972), ('olive oil', 7972), ('water', 7457), ('garlic', 7380), ('sugar', 6434), ('garlic cloves', 6237), ('butter', 4848), ('ground black pepper', 4785), ('all-purpose flour', 4632)]\n",
      "least common ingredients >>> [('tongue', 1), ('Daiya', 1), ('curry mix', 1), ('Kraft Slim Cut Mozzarella Cheese Slices', 1), ('Oscar Mayer Cotto Salami', 1), ('Challenge Butter', 1), ('orange glaze', 1), ('cholesterol free egg substitute', 1), ('ciabatta loaf', 1), ('Lipton® Iced Tea Brew Family Size Tea Bags', 1), ('Hidden Valley® Greek Yogurt Original Ranch® Dip Mix', 1), ('lop chong', 1), ('tomato garlic pasta sauce', 1), ('crushed cheese crackers', 1)]\n"
     ]
    }
   ],
   "source": [
    "ing_2d = list(df['ingredients'])\n",
    "all_ing = [ing for sublist in ing_2d for ing in sublist]\n",
    "# print(all_ing)\n",
    "\n",
    "print(f'number of unique ingredients >> {len(set(all_ing))}')\n",
    "\n",
    "ing_counts = Counter(all_ing)\n",
    "print(f'most common ingredients >>> {ing_counts.most_common(10)}')\n",
    "print(f'least common ingredients >>> {ing_counts.most_common()[6700:]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5\n",
    "Generating a wordcloud with the ingredient names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cloud_dict = Counter(all_ing)\n",
    "\n",
    "cloud = WordCloud(width=1000, height=1000).generate_from_frequencies(word_cloud_dict)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(cloud)\n",
    "plt.axis('off')\n",
    "plt.savefig('graphs_and_vis/ingredient_wordcloud.png', bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6\n",
    "Generating a barplot with the cuisine counts to understand the distribution better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'italian': 7838, 'mexican': 6438, 'southern_us': 4320, 'indian': 3003, 'chinese': 2673, 'french': 2646, 'cajun_creole': 1546, 'thai': 1539, 'japanese': 1423, 'greek': 1175, 'spanish': 989, 'korean': 830, 'vietnamese': 825, 'moroccan': 821, 'british': 804, 'filipino': 755, 'irish': 667, 'jamaican': 526, 'russian': 489, 'brazilian': 467})\n"
     ]
    }
   ],
   "source": [
    "cuisine_counts = Counter(df['cuisine'])\n",
    "print(cuisine_counts)\n",
    "\n",
    "x_ax = [c for c,f in cuisine_counts.most_common()]\n",
    "y_ax = [f for c,f in cuisine_counts.most_common()]\n",
    "bar = sns.barplot(x = x_ax, y = y_ax)\n",
    "for item in bar.get_xticklabels():\n",
    "    item.set_rotation(90)\n",
    "    item.set_color('black')\n",
    "\n",
    "for item in bar.get_yticklabels():\n",
    "    item.set_color('black')\n",
    "\n",
    "bar.figure.savefig('graphs_and_vis/cuisine_counts.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7\n",
    "Checking to see if the number of ingredients could be a feature (whether there are any identifiable patterns with cuisine of a particular type having a longer/shorted ingredient list).\n",
    "This does not seem to be the case since the averages are mostly consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0        1    2    3         4          5\n",
      "0     Ingredient  Average  Min  Max        SD   Variance\n",
      "1          greek    10.18    1   27  3.729461   13.90888\n",
      "2    southern_us     9.63    1   40  3.869404   14.97229\n",
      "3       filipino       10    2   38  3.855135  14.862069\n",
      "4         indian    12.71    1   49  5.016806  25.168342\n",
      "5       jamaican    12.21    2   35  4.763897  22.694713\n",
      "6        spanish    10.42    1   35  4.160919  17.313245\n",
      "7        italian     9.91    1   65  3.806708  14.491022\n",
      "8        mexican    10.88    1   52  4.660183  21.717307\n",
      "9        chinese    11.98    2   38  4.042125  16.338776\n",
      "10       british     9.71    2   30  4.165011  17.347317\n",
      "11          thai    12.55    1   40  4.411794  19.463927\n",
      "12    vietnamese    12.68    1   31  5.256173  27.627355\n",
      "13  cajun_creole    12.62    2   31  4.611601  21.266867\n",
      "14     brazilian     9.52    2   59  5.555139  30.859564\n",
      "15        french     9.82    1   31  4.144744  17.178903\n",
      "16      japanese     9.74    1   34  4.245882  18.027511\n",
      "17         irish      9.3    2   27  3.700505  13.693739\n",
      "18        korean    11.28    2   29   3.87888  15.045713\n",
      "19      moroccan    12.91    2   31  4.799813  23.038207\n",
      "20       russian    10.22    2   25  4.051223  16.412409\n"
     ]
    }
   ],
   "source": [
    "num_ing = dict(zip(cuisine_counts.keys(), [list() for x in cuisine_counts.keys()]))\n",
    "for id, row in df.iterrows():\n",
    "    num_ing[row['cuisine']].append(len(row['ingredients']))\n",
    "tab = [['Ingredient', 'Average', 'Min', 'Max', 'SD', 'Variance']]\n",
    "for c, f in num_ing.items():\n",
    "    tab.append([c, round(statistics.mean(f), 2), min(f), max(f), statistics.stdev(f), statistics.variance(f)])\n",
    "\n",
    "num_ing_df = pd.DataFrame(tab)\n",
    "print(num_ing_df)\n",
    "\n",
    "num_ing_df.to_csv('ingredient_counts.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8\n",
    "Based on the previous step, checking to see whether recipes with a single/few ingredients could be removed.\n",
    "Continuing to include such recipes since the ingredients seem to be strongly correlated, for ex sushi with Japanese cuisine (based on looking at the result, not statistical analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0                         1\n",
      "0       Cuisine                Ingredient\n",
      "1      japanese                sushi rice\n",
      "2    vietnamese        dried rice noodles\n",
      "3        indian      plain low-fat yogurt\n",
      "4        indian           unsalted butter\n",
      "5      japanese                      udon\n",
      "6          thai               sticky rice\n",
      "7        indian                    butter\n",
      "8       mexican            corn tortillas\n",
      "9          thai                   grained\n",
      "10  southern_us      lemonade concentrate\n",
      "11         thai              jasmine rice\n",
      "12       indian           unsalted butter\n",
      "13      italian           cherry tomatoes\n",
      "14       french                    butter\n",
      "15       indian                cumin seed\n",
      "16       french            haricots verts\n",
      "17      mexican             vegetable oil\n",
      "18      spanish           spanish chorizo\n",
      "19      spanish  sweetened condensed milk\n",
      "20     japanese                     water\n",
      "21        greek                    phyllo\n",
      "22       indian           unsalted butter\n"
     ]
    }
   ],
   "source": [
    "tab = [['Cuisine', 'Ingredient']]\n",
    "for id, row in df.iterrows():\n",
    "    if len(row['ingredients']) < 2:\n",
    "        tab.append([row['cuisine'], row['ingredients_str']])\n",
    "\n",
    "print(pd.DataFrame(tab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considered whether to eliminate common ingredients/those that made an appearance in every type of cuisine. Based on the EDA deciding to leave these as is, because removal may result in loss of important decision points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some experiements to determine need for further pre-processing - based on this, stemming was not done since it would remove data (baked potatoes and baking potatoes are completely different ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['baked potatoes', 'baking potatoes', 'baked potato', 'baking potatoe']\n",
      "['baked potato', 'baking potato', 'baked potato', 'baking potatoe']\n",
      "['baked potato', 'baking potato', 'baked potato', 'baking potatoe']\n"
     ]
    }
   ],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "import inflect\n",
    "\n",
    "words = ['baked potatoes', 'baking potatoes', 'BaKeD Potato', 'BAKING POTATOE']\n",
    "p = inflect.engine()\n",
    "wn = WordNetLemmatizer()\n",
    "form = [w.strip().lower() for w in words]\n",
    "print(form)\n",
    "\n",
    "sing = [p.singular_noun(w) or w for w in form]\n",
    "print(sing)\n",
    "\n",
    "lem = [wn.lemmatize(w) for w in sing]\n",
    "print(lem)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad4efc98168ab38b08e64aa2fc02055880fa9a8646a17501f53b605319231c71"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
